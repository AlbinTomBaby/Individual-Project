# -*- coding: utf-8 -*-
"""Albin_Final_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16kdV4Mw1rPb9FlBldRHUmi4V93as6Rhc
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import ace_tools as tools


# Load the dataset
file_path = "/mnt/data/Final football player dataset.xlsx"
df = pd.read_excel(file_path)

# Exploratory Data Analysis (EDA)
# Checking basic statistics
eda_summary = df.describe()

# Visualize correlations between performance metrics and wages
plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

# Histograms of key features
df.hist(bins=30, figsize=(15, 10))
plt.suptitle('Histograms of Key Features')
plt.show()

# Data Preparation for the Model
# Assuming 'Stay/Look for Option' as the target variable (Needs to be defined in the dataset)
df['Target'] = df.apply(lambda row: 1 if row['Performance Metric'] > threshold else 0, axis=1) # Define threshold logic

# Selecting features for the model
features = ['Performance Metric', 'Wages', 'Age', 'Position Code'] # Adjust features accordingly
X = df[features]
y = df['Target']

# Splitting the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Building the model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predicting and evaluating the model
y_pred = model.predict(X_test)

# Output evaluation metrics
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Making predictions on the full dataset
df['Prediction'] = model.predict(X)

# Mapping predictions to human-readable form
df['Future'] = df['Prediction'].apply(lambda x: 'Stay' if x == 1 else 'Look for Better Option')

# Output to Excel
output_df = df[['Player Name', 'Position', 'Team', 'Future']]
output_file = "/mnt/data/Player_Future_Predictions.xlsx"
output_df.to_excel(output_file, index=False)

# Display the EDA summary to the user
tools.display_dataframe_to_user(name="EDA Summary", dataframe=eda_summary)

import pandas as pd
from google.colab import drive
# Loading an Excel file from Google Drive
drive.mount('/content/drive')
# Load the datasets
defensive_action = pd.read_excel('/content/drive/My Drive/defensive action stats.xlsx')
goal_creation = pd.read_excel('/content/drive/My Drive/goal and shot creation stat.xlsx')
passing_stats = pd.read_excel('/content/drive/My Drive/passing stats.xlsx')
player_wages = pd.read_excel('/content/drive/My Drive/Player wages.xlsx')
shooting_stats = pd.read_excel('/content/drive/My Drive/Shooting.xlsx')

selected_col_GCA= ['Player', 'SCA', 'SCA90', 'GCA90']
goal_creation_features = goal_creation[selected_col_GCA]
selected_col_def= ['Player', 'Pos', 'Squad', 'Age', 'Blocks', 'Sh', 'Pass', 'Int', 'Clr', 'Err']
defensive_action_features= defensive_action[selected_col_def]
selected_col_pass= ['Player', 'Cmp%']
passing_stats_features = passing_stats[selected_col_pass]
selected_col_shoot= ['Player', '90s', 'Gls', 'Sh', 'SoT', 'SoT%', 'Sh/90', 'SoT/90', 'G/Sh', 'G/SoT']
shooting_stats_features = shooting_stats[selected_col_shoot]
selected_col_wages= ['Player', 'Weekly Wages', 'Annual Wages']
player_wages_features = player_wages[selected_col_wages]
# Merge datasets on common columns (e.g., 'Player', 'Rk')
# Adjust the merge keys and method depending on the dataset's structure
player_dataset = defensive_action_features.merge(goal_creation_features, on=['Player'], how='outer') \
                            .merge(passing_stats_features, on=['Player'], how='outer') \
                            .merge(player_wages_features, on=['Player'], how='outer') \
                            .merge(shooting_stats_features, on=['Player'], how='outer')

player_dataset = player_dataset.drop_duplicates(subset=['Player'])

player_dataset = player_dataset.rename(columns={
    'Sh_x': 'Shots_blocked',
    'Pass': 'Pass_blocked',
    'Int': 'Interceptions',
    'Clr': 'clearance',
    'Err': 'Mistakes',
    'Cmp%': 'pass_completion_%',
    'Sh_y': 'Sh'
})

# Save the final table to a new Excel file
player_dataset.to_excel('/content/drive/My Drive/final_table.xlsx', index=False)
# Display the final dataframe
print(player_dataset.head())

# Check for missing values
missing_values = player_dataset.isnull().sum()
print(missing_values)

# Display basic info about the dataset
print("Basic Information:")
print(df.info())

print("\nDescriptive Statistics:")
print(df.describe())

# Automated EDA report
profile = ProfileReport(df, title="Professional Players EDA Report", explorative=True)
profile.to_file("Professional_Players_EDA_Report.html")
print("EDA Report saved as 'Professional_Players_EDA_Report.html'.")

# Cleaning: Handle missing values
df.fillna('N/A', inplace=True)

# Feature Engineering: Convert columns to numeric where appropriate
def convert_wage(value):
    try:
        if isinstance(value, str):
            return float(value.replace('â‚¬', '').replace(',', '').strip())
    except:
        return np.nan
    return value

if 'Weekly Wage' in df.columns and 'Market Value' in df.columns:
    df['Weekly Wage'] = df['Weekly Wage'].apply(convert_wage)
    df['Market Value'] = df['Market Value'].apply(convert_wage)
else:
    print("Error: Required columns 'Weekly Wage' or 'Market Value' are missing from the dataset.")

# Select relevant features for training
required_columns = ['Age', 'Appearances', 'Goals', 'Assists', 'Pass Accuracy', 'Tackles',
                    'Interceptions', 'Shots on Target', 'Minutes Played', 'Weekly Wage', 'Market Value']

missing_columns = [col for col in required_columns if col not in df.columns]
if missing_columns:
    print(f"Error: The following required columns are missing from the dataset: {missing_columns}")
    # Handle or exit, as necessary
else:
    X = df[required_columns]

# Assuming there is a 'Future' column indicating the prediction target
if 'Future' in df.columns:
    y = df['Future']
else:
    raise ValueError("The target column 'Future' is missing from the dataset.")

# Convert categorical data if necessary
X = pd.get_dummies(X, drop_first=True)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model Training: Random Forest Classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predictions
y_pred = rf_model.predict(X_test)

# Evaluation
print("Classification Report for Random Forest Classifier:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
plt.figure(figsize=(10, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix for Player Future Prediction')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Save predictions to Excel
if 'Player Name' in df.columns and 'Team' in df.columns:
    output = pd.DataFrame({'Player Name': df.loc[X_test.index, 'Player Name'],
                           'Team': df.loc[X_test.index, 'Team'],
                           'Future Prediction': y_pred})
    output.to_excel('Player_Future_Prediction.xlsx', index=False)
    print("Output saved to 'Player_Future_Prediction.xlsx'.")
else:
    print("Error: 'Player Name' or 'Team' columns are missing from the dataset.")